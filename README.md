# Project Summary
This project will build an ETL pipeline for data lake hosted on S3.
The ETL pipeline will extract data from S3, process them using Spark,
and load back into S3 as a set of dimensional tables.

The transformed data will help analytics team to continue finding
insights for what songs their customers are listening to.

# How to run
Run the etl.py file.
The output will be on S3 at 'project4-outputs' folder.